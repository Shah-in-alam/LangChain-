<h1 align="center">ğŸ¤– LangChain + Gemini + Hugging Face AI Playground </h1>

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10+-blue?logo=python" />
  <img src="https://img.shields.io/badge/LangChain-Framework-orange?logo=chainlink" />
  <img src="https://img.shields.io/badge/Google-Gemini-00A67E?logo=google" />
  <img src="https://img.shields.io/badge/HuggingFace-Transformers-yellow?logo=huggingface" />
  <img src="https://img.shields.io/badge/Status-Active-success?style=flat-square" />
</p>

---

## ğŸŒŸ Overview

This repository is an **AI Integration Sandbox** where Python meets **LangChain**, **Google Gemini**, and **Hugging Face**.  
It allows you to experiment with both **cloud and local LLMs**, pipeline setups, and custom chat interfaces â€” all in one place!  

ğŸ’¬ Ask questions.  
ğŸ§  Run inference locally.  
âš™ï¸ Chain models together.  
ğŸš€ Build and scale intelligent agents.

---

## ğŸ§© Features

âœ¨ **Multi-Model Compatibility**
- Google Gemini 2.5 / Gemini Pro via LangChain  
- Hugging Face models (Zephyr 7B, Mistral 7B, TinyLlama 1B)  
- Local inference using Transformers pipelines  

âš¡ **Framework Power**
- LangChain for orchestration  
- dotenv for key management  
- Local + Cloud hybrid configuration  

ğŸ¨ **Developer Friendly**
- Modular code structure  
- `.env` secret management  
- Works with both CPU and GPU  
- Fully virtual-env isolated  

---

## ğŸ› ï¸ Installation

```bash
# 1ï¸âƒ£ Clone the repo
git clone https://github.com/Shah-in-alam/LangChain-.git
cd ai-langchain-playground

# 2ï¸âƒ£ Create a virtual environment
python -m venv venv
source venv/bin/activate  # (Linux/Mac)
venv\Scripts\activate     # (Windows)

# 3ï¸âƒ£ Install dependencies
pip install -r requirements.txt
